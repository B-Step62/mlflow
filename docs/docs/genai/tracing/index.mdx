import Tabs from "@theme/Tabs"
import TabItem from "@theme/TabItem"
import { APILink } from "@site/src/components/APILink";
import TabsWrapper from "@site/src/components/TabsWrapper";

# MLflow Tracing for LLM Observability

**MLflow Tracing** enhances LLM observability in your applications by capturing the inputs, outputs, and metadata associated with each intermediate step of a request, enabling you to easily pinpoint the source of bugs and unexpected behaviors.

![Tracing Gateway Video](/images/llms/tracing/tracing-top.gif)


## Use Cases Throughout the ML Lifecycle

MLflow Tracing empowers you throughout the end-to-end lifecycle of a machine learning project. Here's how it helps you at each step of the workflow:

<TabsWrapper>
  <Tabs>
    <TabItem value="debugging" label="Build & Debug" default>
    <div class="flex-column">

      <div class="flex-row">
        <div class="flex-item">

          #### Complete Debugging Experience in Your IDE or Notebook

          MLflow's tracing capabilities provide deep insights into what happens beneath the abstractions of GenAI libraries, helping you precisely identify where issues occur.

          You can navigate traces seamlessly **within** your preferred IDE, notebook, or within the [MLflow UI](/genai/tracing/observe-with-traces/ui) eliminating the hassle of switching between multiple tabs or searching through an overwhelming list of traces.


        </div>

        <div class="flex-item padding-md">
          ![Trace Debugging](/images/llms/tracing/genai-trace-debug.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="feedback" label="Human Feedback">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Annotation and Human Feedback

        Evaluating the performance of your GenAI application is crucial, but creating a reliable evaluation dataset can be challenging. Traces serve as a rich data source, helping you build high-quality datasets with precise metrics for internal components like retrievers and tools.

        When combined with [MLflow LLM Evaluation](/genai/eval-monitor), MLflow offers a seamless experience for assessing and improving your application‚Äôs performance.

        </div>

        <div class="flex-item padding-md">
          ![Trace Feedback](/images/llms/tracing/genai-human-feedback.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="evaluation" label="Evaluation">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Evaluate and Enhance Application Quality

        Systematically assessing and improving the quality of your GenAI applications is a core challenge. When combined with [MLflow GenAI Evaluation](/genai/eval-monitor), MLflow offers a seamless experience for assessing and improving your application's quality. MLflow Tracing helps by allowing you to **attach and track [quality feedback](/genai/tracing/collect-user-feedback), and inspect the results of quality evaluations with visibility and transparency into the internals of your application**.

        Traces from both evaluation runs and production monitoring can be explored to identify root causes of quality issues‚Äîfor instance, insufficiently retrieved documents in a RAG system or degraded performance of a specific model. Traces empower you to analyze these issues in detail and iterate quickly.

        </div>

        <div class="flex-item padding-md">
          ![Trace Evaluation](/images/llms/tracing/genai-trace-evaluation.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="production-monitoring" label="Production Monitoring">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Monitor Applications in Production

        Understanding and optimizing the performance of your GenAI applications is crucial for maintaining efficient operations. MLflow Tracing enables you to capture and monitor key operational metrics such as latency and execution timing at each step of your application's execution.

        This comprehensive monitoring capability allows you to track and identify performance bottlenecks within complex pipelines, monitor execution efficiency to ensure optimal operation, and identify areas for performance improvement in your code or model interactions. By understanding where time is spent in your application flow, you can make informed decisions about optimization strategies.

        Integrated with various observability platforms such as Databricks, Datadog, Grafana, and Prometheus, MLflow Tracing provides a comprehensive solution for monitoring your GenAI applications in production.

        Refer to [Monitoring GenAI Application in Production](/genai/tracing/prod-tracing) for more details.

        </div>

        <div class="flex-item padding-md">
          ![Monitoring](/images/llms/tracing/genai-monitoring.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="dataset" label="Dataset Collection">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Create a High-Quality Evaluation Dataset from Real User Traffic

        After evaluating your model using [MLflow LLM Evaluation](/genai/eval-monitor), you can explore auto-generated traces during the evaluation run to identify root causes of quality issues ‚Äî for instance, insufficiently retrieved documents.

        Traces empower you to analyze issues in detail and iterate quickly to enhance the quality of your application.

        </div>

        <div class="flex-item padding-md">
          ![Trace Dataset](/images/llms/tracing/genai-trace-dataset.png)
        </div>
      </div>
    </div>

  </TabItem>
  </Tabs>
</TabsWrapper>


<details>
  <summary>Why Choose MLflow?</summary>

# TODO: Migrate to the same panels as genai/index.html

**ü™Ω Free and Open** - MLflow is open source and 100% FREE. You don't need to pay additional SaaS costs to add observability to your GenAI stack. Your trace data is hosted on your own infrastructure.

**ü•á Standard** - MLflow Tracing is compatible with **OpenTelemetry**, an industry-standard observability spec. You can export your trace data to various services in your existing observability stack, such as Grafana, Prometheus, Datadog, New Relic, and more.

**ü§ù Framework Support** - MLflow Tracing integrates with 20+ GenAI libraries, including OpenAI, LangChain, LlamaIndex, DSPy, and others. See the [Automatic Tracing](#automatic-tracing) section for the full list of supported libraries.

**üîÑ End-to-End** - MLflow is designed for managing the end-to-end machine learning lifecycle. With its model tracking and evaluation capabilities, MLflow empowers you to leverage your trace data fully.

**üë• Community** - MLflow boasts a vibrant Open Source community as a part of the Linux Foundation. With 19,000+ GitHub Stars and 15MM+ monthly downloads, MLflow is a trusted standard in the MLOps/LLMOps ecosystem.

</details>

## Getting started

1. Quickstart Guide (Python)
2. Quickstart Guide (Typescript)
3. Instrument your LLM/GenAI application (more detailed guide for tracing your app)


## One-line Auto Tracing Integrations

MLflow Tracing is integrated with various GenAI libraries and provides one-line automatic tracing experience for each library (and combinations of them!):

```python
import mlflow

mlflow.<library-name>.autolog()  # That it!
```

**Popular Frameworks**:  [OpenAI Agent](/genai/tracing/integrations/listing/openai-agent), [LangChain](/genai/tracing/integrations/listing/langchain), [LangGraph](/genai/tracing/integrations/listing/langgraph), [LlamaIndex](/genai/tracing/integrations/listing/llama_index), [DSPy](/genai/tracing/integrations/listing/dspy), [PydanticAI](/genai/tracing/integrations/listing/pydantic_ai), [AutoGen](/genai/tracing/integrations/listing/autogen), [AG2](/genai/tracing/integrations/listing/ag2), [CrewAI](/genai/tracing/integrations/listing/crewai), [Smolagents](/genai/tracing/integrations/listing/smolagents)

**Model Providers**: [OpenAI](/genai/tracing/integrations/listing/openai), [Anthropic](/genai/tracing/integrations/listing/anthropic), [Bedrock](/genai/tracing/integrations/listing/bedrock), [Gemini](/genai/tracing/integrations/listing/gemini), [LiteLLM](/genai/tracing/integrations/listing/litellm), [Ollama](/genai/tracing/integrations/listing/ollama), [Groq](/genai/tracing/integrations/listing/groq), [Mistral](/genai/tracing/integrations/listing/mistral), [DeepSeek](/genai/tracing/integrations/listing/deepseek)

**Specialized Tools**: [Instructor](/genai/tracing/integrations/listing/instructor),  [txtai](/genai/tracing/integrations/listing/txtai)

For the complete list and detailed integration examples, see the [Automatic Tracing](/genai/tracing/app-instrumentation/automatic) documentation.

## Flexible and Customizable

In addition to the one-line auto tracing experience, MLflow offers Python SDK for manually instrumenting your code and manipulating traces:

- [Instrument a function with `@mlflow.trace` decorator](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis#decorator)
- [Instrument any block of code using context manager](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis#context-manager)
- [Group or annotate traces using sessions](/genai/tracing/attach-tags)
- [Redact PII data from traces](/genai/tracing/app-instrumentation/manual-tracing/fluent-apis#redact-pii-data)
- [Disable tracing globally](/genai/tracing/app-instrumentation/automatic#disabling-tracing)

Refer to the [Tracing SDK Guide](/genai/tracing/app-instrumentation/manual-tracing) for complete details about the SDK.

## Guides


## Production Monitoring

MLflow Tracing is production ready and provides comprehensive monitoring capabilities for your GenAI applications in production environments. The tracing system captures detailed execution information that can be integrated with your existing observability stack through OpenTelemetry standards.

For production deployments, consider using the [Lightweight Tracing SDK](/genai/tracing/lightweight-sdk) (`mlflow-tracing`) that is optimized for reducing the total installation size and minimizing dependencies while maintaining full tracing capabilities.

Read [Production Tracing](/genai/tracing/prod-tracing) for complete guidance on using MLflow Tracing for monitoring models in production and various backend configuration options.


:::note
MLflow Tracing support is available with **MLflow 2.14.0+**, but we strongly recommend **MLflow 3** for the latest features and enhanced production support.
:::
