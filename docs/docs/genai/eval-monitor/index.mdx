import Tabs from "@theme/Tabs"
import TabItem from "@theme/TabItem"
import { CardGroup, TitleCard } from "@site/src/components/Card";
import FeatureHighlights from "@site/src/components/FeatureHighlights";
import ImageBox from "@site/src/components/ImageBox";
import TabsWrapper from "@site/src/components/TabsWrapper";
import TilesGrid from "@site/src/components/TilesGrid";
import TileCard from "@site/src/components/TileCard";
import { MessageSquare, Target, BarChart3, ExternalLink, Bot, Users, CheckCircle, TrendingUp } from "lucide-react";

# Evaluating LLM/Agents with MLflow

MLflow's evaluation and monitoring capabilities help you systematically measure, improve, and maintain the quality of your GenAI applications throughout their lifecycle from development through production.


<ImageBox src="/images/llms/tracing/tracing-top.gif" alt="Evaluating LLM/Agents with MLflow" />

## Evaluation Driven Development

**Evaluation-Driven Development** is an emerging practice that


<TabsWrapper>
  <Tabs>
  <TabItem value="feedback" label="Human Feedback">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Track Annotation and Human Feedbacks

        Human feedback is essential for building high-quality GenAI applications that meet user expectations. MLflow supports collecting, managing, and utilizing feedback from end-users and domain experts.

        Feedbacks are attached to traces and recorded with metadata, including user, timestamp, revisions, etc.

        [Learn more →](/genai/tracing/collect-user-feedback)

        </div>

        <div class="flex-item padding-md">
          ![Trace Feedback](/images/llms/tracing/genai-human-feedback.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="evaluation" label="Automatic Evaluation">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Evaluate and Enhance Quality

        Systematically assessing and improving the quality of GenAI applications is a challenge. Combined with [MLflow GenAI Evaluation](/genai/eval-monitor), MLflow offers a seamless experience for evaluating your applications.

        Tracing helps by allowing you to track quality assessment and inspect the evaluation results with visibility into the internals of the system.

        [Learn more →](/genai/eval-monitor)

        </div>

        <div class="flex-item padding-md">
          ![Trace Evaluation](/images/llms/tracing/genai-trace-evaluation.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="llm-judge" label="LLM-as-a-Judge">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Evaluate and Enhance Quality

        Systematically assessing and improving the quality of GenAI applications is a challenge. Combined with [MLflow GenAI Evaluation](/genai/eval-monitor), MLflow offers a seamless experience for evaluating your applications.

        Tracing helps by allowing you to track quality assessment and inspect the evaluation results with visibility into the internals of the system.

        [Learn more →](/genai/eval-monitor)

        </div>

        <div class="flex-item padding-md">
          ![Trace Evaluation](/images/llms/tracing/genai-trace-evaluation.png)
        </div>
      </div>
    </div>

  </TabItem>

  <TabItem value="production-monitoring" label="Online Monitoring">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Monitor Applications in Production

        Understanding and optimizing GenAI application performance is crucial for efficient operations. MLflow Tracing captures key metrics like latency and token usage at each step, as well as various quality metrics, helping you identify bottlenecks, monitor efficiency, and find optimization opportunities.

        [Learn more →](/genai/tracing/prod-tracing)

        </div>

        <div class="flex-item padding-md">
          ![Monitoring](/images/llms/tracing/genai-monitoring.png)
        </div>
      </div>
    </div>

  </TabItem>
  <TabItem value="dataset" label="Dataset Collection">
    <div class="flex-column">
      <div class="flex-row">
        <div class="flex-item">

        #### Create a High-Quality Dataset from Real World Traffic

        Evaluating the performance of your GenAI application is crucial, but creating a reliable evaluation dataset is challenging.

        Traces from production systems capture perfect data for building high-quality datasets with precise details for internal components like retrievers and tools.

        [Learn more →](/genai/tracing/search-traces/#creating-evaluation-datasets)

        </div>

        <div class="flex-item padding-md">
          ![Trace Dataset](/images/llms/tracing/genai-trace-dataset.png)
        </div>
      </div>
    </div>

  </TabItem>
  </Tabs>
</TabsWrapper>

## Running an Evaluation


1. Dataset
2. Predict function
3. Scorers

## Reviewing Evaluation results


## Next Steps

