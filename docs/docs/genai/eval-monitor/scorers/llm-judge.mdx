# LLM-as-a-Judge in MLflow

--- INSTRUCTION TO AUTHOR ---
This guide shows the usage of LLM judge scorers in MLflow.

This page explains
- What is LLM judge? What problem does it solve? How does it different from heuristic?
- Output format of LLM judge scorer
  - score (yes/no) (TIP message explains why we choose binary over 1-5.)
  - rationale
  - source (LLM_JUDGE)
- List of built-in LLM judge scorers in MLflow (table with link to API doc)
- Customizing LLM judge
  - Bring your own prompt (Guidlines / custom_prompt_judge API)
  - Use different LLM models (the model parameter, supported models, litellm)
  - Further customization? Nudge to custom.mdx that describes @scorer decorator
- How to write a good LLM judge? (Nudge to how to auto-optimize judge prompt (alignment.mdx))

--- END INSTRUCTION TO AUTHOR ---